---
title: "Florence AirBnb pricing"
author: "Julianna Szabo"
date: "1/31/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clear environment
rm(list = ls())

# Descriptive statistics and regressions
library(tidyverse)
library(caret)
library(skimr)
library(grid)
library(glmnet)
library(stargazer)
library(xtable)
library(directlabels)
library(knitr)
library(cowplot)
library(pander)
```

```{r, include=FALSE, "preparation code", echo=FALSE}
# set data dir, load theme and functions
source("/Users/Terez/OneDrive - Central European University/Data_Analysis_03/da_case_studies/ch00-tech-prep/theme_bg.R")
source("/Users/Terez/OneDrive - Central European University/Data_Analysis_03/da_case_studies/ch00-tech-prep/da_helper_functions.R")

use_case_dir <- "DA3_Assignment_1"
data_in <- paste(use_case_dir,"data/clean/", sep = "/")
data_out <- paste(use_case_dir,"data/clean/", sep = "/")
output <- paste0(use_case_dir,"/output/")

options(digits = 3)

# Import raw data

data_url = "https://raw.githubusercontent.com/Julianna-szabo/DA3_Assignment_1/main/data/clean/airbnb_florence_workfile_adj.csv"
data = read.csv(data_url)

# First look at data

glimpse(data)
skim(data)

# Some statistics

data %>%
  group_by(n_accommodates) %>%
  dplyr::summarize(mean_price = mean(price, na.rm=TRUE))

Hmisc::describe(data$price)

# Check to see if there are any duplicates
duplicated(names(data))

# where do we have missing variables now?
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]

# what to do with missing values?
# 1. drop if no target (already did)
data <- data %>%
  drop_na(price)

# 2. imput when few, not that important
data <- data %>%
  mutate(
    n_bathrooms = ifelse(is.na(n_bathrooms), median(n_bathrooms, na.rm = T), n_bathrooms),
    n_beds = ifelse(is.na(n_beds), n_accommodates, n_beds),
    n_bedrooms = ifelse(is.na(n_bedrooms), n_accommodates/2, n_bedrooms),
    f_bathroom=ifelse(is.na(f_bathroom),1, f_bathroom),
    f_minimum_nights=ifelse(is.na(f_minimum_nights),1, f_minimum_nights),
    f_number_of_reviews=ifelse(is.na(f_number_of_reviews),1, f_number_of_reviews),
    ln_beds=ifelse(is.na(ln_beds),0, ln_beds),
  )

# 3. drop columns when many missing not important
to_drop <- c("p_host_response_rate")
data <- data %>%
  select(-one_of(to_drop))

to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]


# 4. Replace missing variables re reviews with zero, when no review + add flags
data <- data %>%
  mutate(
    flag_days_since=ifelse(is.na(n_days_since),1, 0),
    n_days_since =  ifelse(is.na(n_days_since), median(n_days_since, na.rm = T), n_days_since),
    flag_review_scores_rating=ifelse(is.na(n_review_scores_rating),1, 0),
    n_review_scores_rating =  ifelse(is.na(n_review_scores_rating), median(n_review_scores_rating, na.rm = T), n_review_scores_rating),
    flag_reviews_per_month=ifelse(is.na(n_reviews_per_month),1, 0),
    n_reviews_per_month =  ifelse(is.na(n_reviews_per_month), median(n_reviews_per_month, na.rm = T), n_reviews_per_month)
  )

#5, Add category Unknown

data <- data %>% 
  mutate(
    f_parking_type = ifelse(is.na(f_parking_type), "Unknown", f_parking_type),
    parking_type = ifelse(is.na(parking_type), "Unknown", parking_type)
  )

# Look at data
summary(data$price)

# where do we have missing variables now?
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]
```
```{r, include=FALSE, "business logic", echo=FALSE}
###################################
# Business logic- define our prediction problem
###################################

# We will be using only apartments that can accommodate 2-6 people since that is what we are
# trying to price.

# that's gonna be our sample
skimr::skim(data)

# NB all graphs, we exclude  extreme values of price
datau <- subset(data, price<400)

# Distribution of price by type below 400

# Histograms
# price
g3a <- ggplot(data=datau, aes(x=price)) +
  geom_histogram_da(type="percent", binwidth = 10) +
  labs(x = "Price (Euros)",y = "Percent")+
  scale_y_continuous(expand = c(0.00,0.00),limits=c(0, 0.15), breaks = seq(0, 0.15, by = 0.03), labels = scales::percent_format(1)) +
  scale_x_continuous(expand = c(0.00,0.00),limits=c(0,400), breaks = seq(0,400, 50)) +
  theme_bg() 


# lnprice
g3b<- ggplot(data=datau, aes(x=ln_price)) +
  geom_histogram_da(type="percent", binwidth = 0.2) +
  coord_cartesian(xlim = c(2.5, 6.5)) +
  scale_y_continuous(expand = c(0.00,0.00),limits=c(0, 0.15), breaks = seq(0, 0.15, by = 0.05), labels = scales::percent_format(5L)) +
  scale_x_continuous(expand = c(0.00,0.01),breaks = seq(2.4,6.6, 0.6)) +
  labs(x = "ln(price, Euros)",y = "Percent")+
  theme_bg() 

# Boxplot
g4 <- ggplot(datau, aes(x = factor(n_accommodates), y = price,
                        fill = factor(f_neighbourhood_cleansed), color=factor(f_neighbourhood_cleansed))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  labs(x = "Accomodates (Persons)",y = "Price (US dollars)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 400), breaks = seq(0,400, 50))+
  theme_bg() +
  theme(legend.position = c(0.3,0.8)        )
```


There seems to be an abundance of AirBnbs in Florence so it is important to stand out. First, the distribution of apartments by the number of people who can stay there. The apartment in question can accommodate 2 to 6 people, so that is the range of interest. Further, it would also be nice to see the distribution within Neighbourhoods, since the competition may be more intense in one compared to the other.  

```{r, echo=FALSE, message=FALSE, error=FALSE, "Distribution graph"}
plot_dist <- ggplot(data = datau, aes(x = factor(n_accommodates), color = f_neighbourhood_cleansed, fill = f_neighbourhood_cleansed)) +
  geom_bar(alpha=0.8, na.rm=T, width = 0.8) +
  labs(x = "Accomodates (Persons)",y = "Frequency")+
  theme_bg() +
  theme(legend.position = "top")
plot_dist
```

As can be seen, most apartments are located in the old town. This is not very surprising since that is the most touristy area of any city. Let us see how that affects the price. The graph focuses on the number of people the apartment can accommodate, while also showing the difference within neighbourhoods.

```{r, echo=FALSE, "Accommodation Dist"}
g4 <- ggplot(datau, aes(x = factor(n_accommodates), y = price,
                        fill = factor(f_neighbourhood_cleansed), color=factor(f_neighbourhood_cleansed))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  labs(x = "Accomodates (Persons)",y = "Price (US dollars)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 400), breaks = seq(0,400, 50))+
  theme_bg() +
  theme(legend.position = c(0.3,0.8)        )
g4
```


With the expecting of 3 people appartments, the old town is always the most expensive. Further, it can be seen that this is an important factor since the price does steadily increase with more people able to stay at the apartment. However, it seems that it is not the only factor influencing the price. Therefore, models have been developed that can better explain the change in price.  

First, there are simple linear models. These examine the correlalation between each x variables and price.  

```{r, echo=FALSE, include=FALSE, "Model setup"}

#####################
# Setting up models #
#####################

# Basic Variables
basic_lev  <- c("n_accommodates","n_bedrooms", "n_beds", "n_days_since", "flag_days_since",
                "f_parking_free_vs_paid", "f_neighbourhood_cleansed")

# Factorized variables
basic_add <- c("f_bathroom", "f_parking_on_vs_off_premises", "f_parking_type")
reviews <- c("f_number_of_reviews","n_review_scores_rating", "flag_review_scores_rating")
# Higher orders
poly_lev <- c("n_accommodates2", "n_days_since2", "n_days_since3")

#not use p_host_response_rate due to missing obs

# Dummy variables: Extras -> collect all options and create dummies
amenities <-  grep("^d_.*", names(data), value = TRUE)


#################################################
# Look for interactions
################################################

#Look up room type interactions
p1 <- price_diff_by_variables2(data, "f_neighbourhood_cleansed", "d_gardenorbackyard", "Neighbourhood", "Garden or backyard")
p2 <- price_diff_by_variables2(data, "f_neighbourhood_cleansed", "d_luggagedropoffallowed", "Neighbourhood", "Luggage drop off")
#Look up property type
p3 <- price_diff_by_variables2(data, "f_neighbourhood_cleansed", "d_petsallowed", "Neighbourhood", "Pets allowed")
p4 <- price_diff_by_variables2(data, "f_neighbourhood_cleansed", "d_elevator",  "Neighbourhood", "Elevator")
#Look up parking
p5 <- price_diff_by_variables2(data, "f_parking_free_vs_paid", "d_luggagedropoffallowed", "Parking", "Luggage drop off")
p6 <- price_diff_by_variables2(data, "f_parking_free_vs_paid", "d_suitableforevents", "Parking", "Suitable for events")

g_interactions <- plot_grid(p1, p2, p3, p4, p5, p6, nrow=3, ncol=2)
g_interactions


# dummies suggested by graphs
X1  <- c("f_neighbourhood_cleansed*d_gardenorbackyard", "f_neighbourhood_cleansed*d_petsallowed",
         "f_neighbourhood_cleansed*d_elevator")

# Additional interactions of factors and dummies
X2  <- c("d_airconditioning*f_neighbourhood_cleansed", "d_gym*f_neighbourhood_cleansed")
X3  <- c(paste0("(f_neighbourhood_cleansed + f_parking_free_vs_paid) * (",
                paste(amenities, collapse=" + "),")"))


# Create models in levels models: 1-8
modellev1 <- " ~ n_accommodates"
modellev2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
modellev3 <- paste0(" ~ ",paste(c(basic_lev, basic_add,reviews),collapse = " + "))
modellev4 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev),collapse = " + "))
modellev5 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev,X1),collapse = " + "))
modellev6 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev,X1,X2),collapse = " + "))
modellev7 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev,X1,X2,amenities),collapse = " + "))
modellev8 <- paste0(" ~ ",paste(c(basic_lev,basic_add,reviews,poly_lev,X1,X2,amenities,X3),collapse = " + "))


#################################
# Separate hold-out set #
#################################

# create a holdout set (20% of observations)
smp_size <- floor(0.2 * nrow(data))

# Set the random number generator: It will make results reproducable
set.seed(20180123)

# create ids:
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
holdout_ids <- sample(seq_len(nrow(data)), size = smp_size)
data$holdout <- 0
data$holdout[holdout_ids] <- 1

#Hold-out set Set
data_holdout <- data %>% filter(holdout == 1)

#Working data set
data_work <- data %>% filter(holdout == 0)


##############################
#      cross validation      #
##############################

## N = 5
n_folds=5
# Create the folds
set.seed(20180124)

folds_i <- sample(rep(1:n_folds, length.out = nrow(data_work) ))
# Create results
model_results_cv <- list()
 
for (i in (1:8)){
  model_name <-  paste0("modellev",i)
  model_pretty_name <- paste0("(",i,")")
  
  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  
  # Initialize values
  rmse_train <- c()
  rmse_test <- c()
  
  model_work_data <- lm(formula,data = data_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared
  
  # Do the k-fold estimation
  for (k in 1:n_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    data_train <- data_work[-test_i, ]
    # Test sample
    data_test <- data_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = data_train)
    prediction_train <- predict(model, newdata = data_train)
    prediction_test <- predict(model, newdata = data_test)
    
    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, data_train$price)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, data_train$price)**(1/2)
    
  }
  
  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_pretty_name, nvars = nvars, r2 = r2)
}


model <- lm(formula,data = data_train)
prediction_train <- predict(model, newdata = data_train)
prediction_test <- predict(model, newdata = data_test)

skim(data_train$ln_days_since)

t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()

# RMSE training vs test graph
t1_levels <- t1 %>%
  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  gather(var,value, rmse_train:rmse_test) %>%
  mutate(nvars2=nvars+1) %>%
  mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                      labels = c("RMSE Training","RMSE Test")))

model_result_plot_levels <- ggplot(data = t1_levels,
                                   aes(x = factor(nvars2), y = value, color=factor(var), group = var)) +
  geom_line(size=1,show.legend=FALSE, na.rm = TRUE) +
  scale_color_manual(name="",
                     values=c(color[2],color[1])) +
  scale_x_discrete( name = "Number of coefficients", expand=c(0.01, 0.01)) +
  geom_dl(aes(label = var),  method = list("last.points", dl.trans(x=x-1), cex=0.4)) +
  #scale_colour_discrete(guide = 'none') +
  theme_bg()
```
```{r, echo=FALSE}
pander(t1)
```
It is visible that based on RMSE the best model is number 1 with the lowest Root Mean Square Error (RMSE). However, using BIC as the deciding measurement the best model would be number 5. Therefore we will later see which one we wwant to use. The difference between the two both in terms of RMSE and BIC is minimal, however model choice may affect predicted values. 

```{r, echo=FALSE}
model_result_plot_levels
```

A LASSO model was also created which returned 52 variables as significant. This number is almost double the variables as the simple linear models had. This can be explained by the types of variables picked by LASSO. They were mainly interaction variables, which were not considered in most of the linear models. The LASSO model does outperform all the linear models based on RMSE, since it has an RMSE of 60.8.  

INSERT TABLE WITH RMSE VALUES

Through both the linear models and LASSO, the most important factors influencing price have been discovered.  

Some of the most influential are as expected:  
  * Number of bedrooms  
  * Number of people it fits  
Some interesting factors that seem to be important are:  
  * Availability of a dishwasher  
  * Possibility for luggage drop off  
  * Number of reviews recieved  
  * Availability of an elevator  
Some factors that were expected to be important, but turned to be insignificant are:  
  * If pets are allowed in the space  
  * If the apartment has a balcony  
  * Availability of a rooftop  
  * Availability of a safe  

```{r cars}
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
